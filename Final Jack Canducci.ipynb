{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS407 Machine Learning Final\n",
    "\n",
    "## By: Jack Canducci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'MLLibrary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_99190/2892365872.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mMLLibrary\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Hypothesis Testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'MLLibrary'"
     ]
    }
   ],
   "source": [
    "# General Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import MLLibrary as ml\n",
    "\n",
    "# Hypothesis Testing\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Fuzzy Matching\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from textdistance import levenshtein\n",
    "from textdistance import jaro_winkler\n",
    "from textdistance import jaccard\n",
    "\n",
    "# Linear Programming\n",
    "from pulp import LpVariable\n",
    "from pulp import LpSolver\n",
    "from pulp import LpProblem\n",
    "from pulp import LpStatus\n",
    "from pulp import LpInteger\n",
    "from pulp import LpMaximize\n",
    "from pulp import LpMinimize\n",
    "\n",
    "# Data Setup\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Model Training / Testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "# Regressors\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://inria.github.io/scikit-learn-mooc/python_scripts/datasets_california_housing.html\n",
    "californiaHousing = fetch_california_housing()\n",
    "\n",
    "data = californiaHousing.data\n",
    "target = californiaHousing.target\n",
    "\n",
    "dataTrain, dataTest, targetTrain, targetTest = train_test_split(data, target, test_size=0.25)\n",
    "\n",
    "# Needed for NN\n",
    "standardScaler = StandardScaler()\n",
    "scaledDataTrain = standardScaler.fit_transform(dataTrain)\n",
    "scaledDataTest = standardScaler.transform(dataTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.5378425015997423\n",
      "Mean Squared Error: 0.5561263424248348\n",
      "Root Mean Squared Error: 0.7457387896742631\n"
     ]
    }
   ],
   "source": [
    "linearRegression_model = LinearRegression()\n",
    "\n",
    "linearRegression_model.fit(dataTrain, targetTrain)\n",
    "\n",
    "targetPrediction = linearRegression_model.predict(dataTest)\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(targetTest, targetPrediction))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(targetTest, targetPrediction))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(targetTest, targetPrediction))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.4558868352713179\n",
      "Mean Squared Error: 0.5116152133218411\n",
      "Root Mean Squared Error: 0.7152728243976847\n"
     ]
    }
   ],
   "source": [
    "decisionTreeRegressor_model = DecisionTreeRegressor()\n",
    "\n",
    "decisionTreeRegressor_model.fit(dataTrain, targetTrain)\n",
    "\n",
    "targetPrediction = decisionTreeRegressor_model.predict(dataTest)\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(targetTest, targetPrediction))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(targetTest, targetPrediction))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(targetTest, targetPrediction))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.32568516170542655\n",
      "Mean Squared Error: 0.2525042512946152\n",
      "Root Mean Squared Error: 0.5024980112344876\n"
     ]
    }
   ],
   "source": [
    "randomForestRegressor_model = RandomForestRegressor(n_estimators=100, random_state=0)  \n",
    "\n",
    "randomForestRegressor_model.fit(dataTrain, targetTrain)  \n",
    "\n",
    "targetPrediction = randomForestRegressor_model.predict(dataTest)  \n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(targetTest, targetPrediction))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(targetTest, targetPrediction))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(targetTest, targetPrediction))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.3371878702003033\n",
      "Mean Squared Error: 2.9457267133563194\n",
      "Root Mean Squared Error: 1.7163119510614377\n"
     ]
    }
   ],
   "source": [
    "multiLayerPerceptronRegressor_model = MLPRegressor(hidden_layer_sizes=(64,64,64),activation=\"relu\" ,random_state=1, max_iter=2000)\n",
    "\n",
    "multiLayerPerceptronRegressor_model.fit(dataTrain, targetTrain)\n",
    "\n",
    "targetPrediction = multiLayerPerceptronRegressor_model.predict(dataTest)\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(targetTest, targetPrediction))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(targetTest, targetPrediction))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(targetTest, targetPrediction))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the lowest set of errors were coming from my random forest, it seems as though the highest is coming from my neural network. I assume that's due to an underlying factor of how these systems for regression are applicable. My general linear regression model and my decision tree were very in between these two. This shows that my other two models were more middle grounds between the NN and the RF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pima = pd.read_csv(\"CSV/pima-indians-diabetes.csv\")\n",
    "\n",
    "data_mod = pima[(pima.BloodP != 0) & (pima.BMI != 0) & (pima.Glucose != 0)]\n",
    "\n",
    "data = ['Pregnancies', 'Glucose', 'BloodP', 'SkinThick', 'BMI', 'Age', 'Insulin', 'DiabetesPedigreeFunction']\n",
    "target = \"Outcome\"\n",
    "\n",
    "#dataTrain, dataTest, targetTrain, targetTest = train_test_split(data_mod, test_size=0.25)\n",
    "train, test = train_test_split(data_mod, test_size=0.25)\n",
    "\n",
    "standardScaler = StandardScaler()\n",
    "dataTrainScaled=standardScaler.fit_transform(train[data])\n",
    "dataTestScaled=standardScaler.transform(test[data])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  71.27 %\n"
     ]
    }
   ],
   "source": [
    "naiveBayes_model = GaussianNB()\n",
    "\n",
    "naiveBayes_model.fit(train[data], train[target])\n",
    "\n",
    "targetPrediction = naiveBayes_model.predict(test[data])\n",
    "\n",
    "print('Accuracy Score: ', round(accuracy_score(test[target], targetPrediction)*100, 2), '%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  72.38 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/septri/.local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logisticRegression_model = LogisticRegression()\n",
    "\n",
    "logisticRegression_model.fit(train[data], train[target])\n",
    "\n",
    "targetPrediction = logisticRegression_model.predict(test[data])\n",
    "\n",
    "print('Accuracy Score: ', round(accuracy_score(test[target], targetPrediction)*100, 2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  69.61 %\n"
     ]
    }
   ],
   "source": [
    "decisionTreeClassifier_model = DecisionTreeClassifier()\n",
    "\n",
    "decisionTreeClassifier_model.fit(train[data], train[target])\n",
    "\n",
    "targetPrediction = decisionTreeClassifier_model.predict(test[data])\n",
    "\n",
    "print('Accuracy Score: ', round(accuracy_score(test[target], targetPrediction)*100, 2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  71.27 %\n"
     ]
    }
   ],
   "source": [
    "randomForestClassifier_model = RandomForestClassifier()\n",
    "\n",
    "randomForestClassifier_model.fit(train[data], train[target])\n",
    "\n",
    "targetPrediction = randomForestClassifier_model.predict(test[data])\n",
    "\n",
    "print('Accuracy Score: ', round(accuracy_score(test[target], targetPrediction)*100, 2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  67.4 %\n"
     ]
    }
   ],
   "source": [
    "multiLayerPerceptronClassifier_model = MLPClassifier(hidden_layer_sizes=(256,128,64,32),activation=\"relu\",random_state=1)\n",
    "\n",
    "multiLayerPerceptronClassifier_model.fit(dataTrainScaled, train[target])\n",
    "\n",
    "targetPrediction = multiLayerPerceptronClassifier_model.predict(dataTestScaled)\n",
    "\n",
    "print('Accuracy Score: ', round(accuracy_score(test[target], targetPrediction) * 100, 2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of all my models, my logistic model actually did the best which is surprising to me. I would have assumed that the NN would do best but it seems it nearly did the worst. Naive Bayes did a little worse with an accuracy score of 74.59% followed by the decision tree, MLP NN, and then the random forest. I'm a little confused about why the random forest did poorly compared to the others so I'll explore more into this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringOne = \"Machine Learning is fun\"\n",
    "stringTwo = \"Professor Utpal has made me enjoy this subject. That is a feat.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.ratio(stringOne, stringTwo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.partial_ratio(stringOne, stringTwo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token Sort Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.token_sort_ratio(stringOne, stringTwo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token Set Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.token_set_ratio(stringOne, stringTwo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Levenshtein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshtein.distance(stringOne, stringTwo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaro-Winker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5087416609155739"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaro_winkler.distance(stringOne, stringTwo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7714285714285715"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard.distance(stringOne, stringTwo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /home/septri/.local/lib/python3.9/site-packages/pulp/apis/../solverdir/cbc/linux/64/cbc /tmp/d85e455232d440e19fa537a02ba69f46-pulp.mps max timeMode elapsed branch printingOptions all solution /tmp/d85e455232d440e19fa537a02ba69f46-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 8 COLUMNS\n",
      "At line 21 RHS\n",
      "At line 25 BOUNDS\n",
      "At line 26 ENDATA\n",
      "Problem MODEL has 3 rows, 6 columns and 6 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Presolve 0 (-3) rows, 0 (-6) columns and 0 (-6) elements\n",
      "Empty problem - 0 rows, 0 columns and 0 elements\n",
      "Optimal - objective value 1408\n",
      "After Postsolve, objective 1408, infeasibilities - dual 0 (0), primal 0 (0)\n",
      "Optimal objective 1408 - 0 iterations time 0.002, Presolve 0.00\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.00   (Wallclock seconds):       0.00\n",
      "\n",
      "AdditionalOne = 0.0\n",
      "AdditionalTwo = 16.0\n",
      "ExtrusionOne = 12.0\n",
      "ExtrusionTwo = 0.0\n",
      "PackagingOne = 0.0\n",
      "PackagingTwo = 9.0\n"
     ]
    }
   ],
   "source": [
    "problem = LpProblem(\"Stratton\", LpMaximize)\n",
    "\n",
    "extrusionType1 = LpVariable(\"ExtrusionOne\",lowBound=0,cat='Continuous')\n",
    "packagingType1 = LpVariable(\"PackagingOne\",lowBound=0, cat='Continuous')\n",
    "additionalType1 = LpVariable(\"AdditionalOne\", lowBound=0, cat='Continuous')\n",
    "\n",
    "extrusionType2 = LpVariable(\"ExtrusionTwo\",lowBound=0,cat='Continuous')\n",
    "packagingType2 = LpVariable(\"PackagingTwo\",lowBound=0, cat='Continuous')\n",
    "additionalType2 = LpVariable(\"AdditionalTwo\", lowBound=0, cat='Continuous')\n",
    "\n",
    "problem += (34 * (extrusionType1 + packagingType1 + additionalType1)) + (40 * (extrusionType2 + packagingType2 + additionalType2))\n",
    "\n",
    "problem += (extrusionType1 * 4) + (extrusionType2 * 6) <= 48\n",
    "problem += (packagingType1 * 2) + (packagingType2 * 2) <= 18\n",
    "problem += (additionalType1 * 2) + (additionalType2 * 1) <= 16 \n",
    "\n",
    "problem.solve()\n",
    "LpStatus[problem.status]\n",
    "\n",
    "for variable in problem.variables():     # Print the Variable values for Optimized Objective\n",
    "    print(variable.name, '=', variable.varValue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the CBC MILP Solver \n",
      "Version: 2.10.3 \n",
      "Build Date: Dec 15 2019 \n",
      "\n",
      "command line - /home/septri/.local/lib/python3.9/site-packages/pulp/apis/../solverdir/cbc/linux/64/cbc /tmp/50e7d3f78fbb4b618cb651987824fd47-pulp.mps max timeMode elapsed branch printingOptions all solution /tmp/50e7d3f78fbb4b618cb651987824fd47-pulp.sol (default strategy 1)\n",
      "At line 2 NAME          MODEL\n",
      "At line 3 ROWS\n",
      "At line 7 COLUMNS\n",
      "At line 14 RHS\n",
      "At line 17 BOUNDS\n",
      "At line 18 ENDATA\n",
      "Problem MODEL has 2 rows, 2 columns and 4 elements\n",
      "Coin0008I MODEL read with 0 errors\n",
      "Option for timeMode changed from cpu to elapsed\n",
      "Presolve 2 (0) rows, 2 (0) columns and 4 (0) elements\n",
      "0  Obj -0 Dual inf 90 (2)\n",
      "0  Obj -0 Dual inf 90 (2)\n",
      "2  Obj 28750\n",
      "Optimal - objective value 28750\n",
      "Optimal objective 28750 - 2 iterations time 0.002\n",
      "Option for printingOptions changed from normal to all\n",
      "Total time (CPU seconds):       0.00   (Wallclock seconds):       0.00\n",
      "\n",
      "Jackets = 250.0\n",
      "Pants = 375.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/septri/.local/lib/python3.9/site-packages/pulp/pulp.py:1313: UserWarning: Spaces are not permitted in the name. Converted to '_'\n",
      "  warnings.warn(\"Spaces are not permitted in the name. Converted to '_'\")\n"
     ]
    }
   ],
   "source": [
    "problem2 = LpProblem(\"Problem 2\", LpMaximize)\n",
    "\n",
    "pants = LpVariable(\"Pants\", lowBound=0, cat='Continuous')\n",
    "jackets = LpVariable(\"Jackets\", lowBound=0, cat='Continuous')\n",
    "\n",
    "problem2 += (50 * (pants)) + (40 * (jackets))\n",
    "\n",
    "problem2 += (pants * 1) + (jackets * 1.5) <= 750\n",
    "problem2 += (pants * 2) + (jackets * 1) <= 1000\n",
    "\n",
    "problem2.solve()\n",
    "LpStatus[problem2.status]\n",
    "\n",
    "for variable in problem2.variables():     # Print the Variable values for Optimized Objective\n",
    "    print(variable.name, '=', variable.varValue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-score =  -0.10714285714285725\n",
      "p-value =  0.4573378238740764\n"
     ]
    }
   ],
   "source": [
    "x_bar = 1.39\n",
    "µ = 1.48\n",
    "s_dev = 0.84\n",
    "z_score = (x_bar - µ)/s_dev\n",
    "print(\"Z-score = \", z_score)\n",
    "p_value = norm.cdf(z_score) # since it is a Two Tail test\n",
    "print(\"p-value = \",p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-score =  -1.750000000000007\n",
      "p-value =  0.040059156863816475\n"
     ]
    }
   ],
   "source": [
    "x_bar = 160.1\n",
    "µ = 162.9\n",
    "s_dev = 1.6\n",
    "z_score = (x_bar - µ)/s_dev\n",
    "print(\"Z-score = \", z_score)\n",
    "p_value = norm.cdf(z_score) # since it is a Left Tail test\n",
    "print(\"p-value = \",p_value)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
